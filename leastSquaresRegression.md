<!-- Least Squares Regression -->

##  In the special case of linear relationship, use the least squares regression line as a summary of the overall pattern, and use it to make predictions ##

1. Regression
  - The technique that specifies the dependence of the response variable on the explanatory variable is called "Regression"
  - When that dependence is "Linear" the technique is called "Linear Regression" 
  - Linear Regression finds the line that BEST FITS the pattern of the linear relationship, or in other words, the line that BEST describes HOW the response variable linearly DEPENDS on the explanatory variable

2. Least Squares Criterion
  - This criterion is set to choose the line that has the smallest sum of squared vertical deviations 
  - See Stanford Statistics: Case Q -> Q Under "Least Squares Regression"
  
3. The Algebra of a Line 
  - A "Line" is described by a set of points (X,Y) that obey a particular relationship between X and Y 
  - That relationship is called the "Equation of a Line" 
  - The constants "a" and "b", which can be negative or positive, tell us what the line looks like 
  ## Equation of a Line Formula ## 
    Y = a + bX 
    a: The intercept (a) is the value that Y takes when X = 0 
    b: The slope (b) is the change in Y for every increase of 1 unit in X
    
4. Least-Squares Regression Line
  - The equation for summarizing the Linear Relationship between the Response/Dependent Variable (Y) and the Explanatory/Independent Variable (X) has the form: Y = a + bX
  - However, we have to calculate the value of "a" and "b" > For this, we will need the following:
    - _X: the MEAN of the Explanatory Variable's value 
    ## that is X with a line over the top, but can't do in text editor ## 
    - Sx: the STANDARD DEVIATION of the Explanatory Variable's values 
    ## that is S sub x (x is below the S) ##
    - _Y: the MEAN of the Response Variable's values
    ## that is Y with a line over the top, but can't do in text editor ##
    - Sy: the STANDARD DEVIATION of the Response Variable's values
    ## that is S sub y (y is below the S) ##
    - r: Correlation Coefficient 
  - Given the above values, the SLOPE (b) and INTERCEPT (a) of the Least Squares Regression Line are found using the following formulas: 
      b = r (Sy/Sx) >>>> Remember this is S sub y and S sub x
      a = _Y - b_X >>>>> This is Y with a line on top and X with a line on top 
  - The slope of the Least Squares Regression Line can be interpreted as the average change in response variable when the Explanatory Variable increases by 1 unit 
  
  ## IMPORTANT: Since the formula for the intercept (a) depends on the values of the slope (b) you have to calculate the SLOPE FIRST ##     
      
      
      
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  